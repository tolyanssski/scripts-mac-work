# AGENTS: базовые ожидания по задачам

Этот файл — шпаргалка по типовым требованиям во всех git-проектах в `~/projects`.
Все эти проекты являются частью одного большого продукта: каждый проект - это или микросервис, или общая библиотека, используемая другими проектами. 
Пользуйся текущей шпаргалкой как стартовой инструкцией.
Если новая задача похожа на один из кейсов ниже — применяй соответствующий набор действий без повторных подсказок.

## Работа с миграциями

Несмотря на то, что в проектах используются ORM-системы (либо ent, либо gorm), миграции у нас все ручные в виде простых SQL-файлов для Postgres.
У некоторых проектов есть своя БД, и соответственно своя папка migrations (лежит всегда в корне проекта), 
куда надо складывать новые файлы с миграциями. Если в проекте используется Atlas,
то нужно сгенерировать atlas.sum.

Но также есть проекты, у которых своей БД нет (используется общая), и миграции лежат
в отдельном git-проекте.
Если ты работаешь над таким проектом и тебе требуется сделать миграцию, но в проекте нет папки migrations (в корне проекта), просто создай новую папку migrations и
добавь туда SQL-файл. Я потом сам руками ее перенесу куда надо.

В проектах нужно создавать только UP-миграции. Миграций "down" (отката сделанных изменений) создавать не нужно.

### Формат файла миграций

Миграции складываются в папку migrations в корне проекта. Формат: SQL-файл,
с именем в формате `<YYYYMMDDhhmmss>_<названиеМиграцииНаАнгл>.sql`. Где `<YYYYMMDDhhmmss>` - текущее дата/время в заданном формате, например: 20260114090857 (пример для текущего даты/времени 2025-01-14 09:08:57).

### В каких случаях требуется создание новой миграции

Если в задаче ничего не написано про миграции, но при этом выполнение задачи
подразумевает создание новой или изменение существующей ORM-сущности (в ent/gorm),
всегда делай новую миграцию с этими изменениями, в соответствии с инструкцией выше. 

## Общие подходы

- По умолчанию в качестве идентификаторов везде используй uuid v7;
- Всегда обновляй сущности вместе с инфраструктурой: поля в ent/gorm + миграции Postgres, правки репозиториев, DTO, сервисных слоев, OpenAPI/gRPC, тестов и данных (data-migration скрипты, если нужно проставить значения старым строкам).
- Конфиги с secrets/creds/external_urls дублируй env-переменными: значения должны идти из YAML, но переопределяться через переменные окружения. Данный пункт касается только значений конфига, содержащих те или иные credentials для подключения к внешним системам (secret key, api key, external_system_url и аналогичные). 
- Локи обязательны при гонках: ключи строятся из сервиса/метода и бизнес-идентификаторов (userID, accountID, address и т.п.), TTL ставят только если явно указано.
- Побочные эффекты (Kafka producing, отправка e-mail/SMS, создание/отправка уведомлений) выноси из БД-транзакций; ошибки уведомлений чаще логируются и не прерывают основной флоу.

## Работа с зависимостями пакета/сервиса

Под "сервисом" внутри проекта подразумевается структура, лежащая внутри какого-либо пакета, имеющая свой конструктор, зависимости и публичные/приватные методы.

Если требуется добавить зависимость в сервис, то как правило нужно сначала
в пакете сервиса создать локальный интерфейс, описывающий методы (подсмотри методы в конкретной зависимости). После этого в конструктор сервиса пробрасывай аргументом
этот локальный интерфейс. А уже на уровне DI (на этапе сборки приложения) подставляй
конкретный инстанс этой зависимости.

Если зависимость проброшена через конструктор сервиса и является его приватным полем,
то подразумевай что во всех рабочих методах сервиса это поле точно не nil.
Можешь проверять на nil прямо конструкторе и возвращать из конструктора error, но это
не обязательно.
Проверять на nil эти поля-зависимости в рабочей логике не нужно.

## Работа с Locker

В проектах при работе с сущностями часто используется паттерн `pessimitic offline lock` (by Martin Fowler). Это значит в ряде задач (особенно выполняющихся в фоне)
перед началом работы с сущностью (апдейтом и тд) ставится лок путем создания специальной временной записи в БД или Redis или еще каком-либо хранилище.
В нашем продукте во всех проектах и сервисах используется лок через Redis. В проектах
проброшен стандартный Locker из общей библиотеки. Он реализует интерфейс Locker.

Если требуется поставить лок на сущность/какой-то другой идентификатор в логике какого-то сервиса, делай следующее:
- убедись что у этого сервиса уже есть зависимость Locker. Если нет, пробрось через DI;
- работу с залоченной сущностью/другим идентификатором по умолчанию выноси в отдельный приватный метод-обработчик;
- в методе-обработчике в самом начале ставь лок, потом после обработки ошибки сразу же defer unlock с этим же ключом;
- ключ каждого лока должен быть строкой в формате: `<project_name>:<package_name>:<structure_name>:<method_name>:<ID>`, где ID - это либо ID блокируемой сущности (если блокируется сущность), либо само значение блокируемого идентификатора (если блокируется что-то другое);
- никогда не делай сборку ключа лока inline: выноси сборку в специальный приватный метод - билдер лок-ключа (под каждый лок свой метод-билдер);

### Важное про реализацию метода-обработчика, если блокируется сущность БД

Если ставится лок на БД-сущность, то в метод-обработчик пробрасывай на экземпляр сущности, а только ее ID.
После установки лока в методе-обработчике делай заново получение инстанса сущности из репозитория по ее ID, чтобы гарантировать что обработка сущности будет идти со свежими данными, актуальными на момент успешного лока.

## Работа с воркерами / фоновыми горутинами

В контексте наших проектов слова "воркер" и "фоновая горутина" - синонимы.
Воркер - это отдельный сервис внутри проекта, который запускается в фоновом режиме
одновременно со стартом всего приложения, в виде самостоятельной горутины.
Воркер имеет метод запуска `Run(ctx) error`, на входе ему подается базовый контекст
приложения. Метод должен быть блокирующим, и единственный способ выхода из метода - это возвращенная ошибка.
Следовательно запускать надо при старте приложения как часть errgroup или аналогов.

Пример кода, запускающего воркеры (app.Run() всего приложения со всеми воркерами внутри):

```go
func (a *App) Run(ctx context.Context) error {
	ctx, cancel := context.WithCancel(ctx)
	go func() {
		<-a.done
		cancel()
	}()

	errs := make(chan error)

	go func() {
		err := a.eventsService.Run(ctx)
		if err != nil {
			select {
			case errs <- errors.Wrap(err, "eventsService.Run"):
			case <-ctx.Done():
			}
			return
		}
	}()

	go func() {
		err := a.rightsService.Run(ctx)
		if err != nil {
			select {
			case errs <- errors.Wrap(err, "rightsService.Run"):
			case <-ctx.Done():
			}
			return
		}
	}()

	select {
	case err := <-errs:
		_ = a.Shutdown()
		return err
	case <-ctx.Done():
		return nil
	}
}
```

Если в конкретном проекте используется другой подход к запуску фоновых воркеров, используй его (встраивай новый воркер в уже сложившийся код запуска).

### Что делать, если требуется создать новый воркер

- Если не сказано иное, создай новый пакет, и внутри него сервис с названием таким же как пакет. Если не указано как его назвать, придумай название сам на основе того что будет делать этот новый воркер;
- Пробрось в него зависимости через DI: как минимум Logger и Locker обязательно, а также Kafka consumer, если это кафка-воркер. А также те зависимости что требуются в задаче;
- Реализуй метод Run(): способ реализации зависит от типа воркера, смотри пункты ниже.

#### БД-воркеры

БД-воркер - это просто бесконечный цикл, который раз в определенный период времени
делает запрос в БД по заданным критериям, получает выборку сущностей и далее 
производит обработку каждой сущности в отдельном приватном методе.

В некоторых случаях может быть не выборка сущностей, а выборка каких-либо других данных.

Получив выборку, проходишься по всему полученному массиву, дергаешь приватный метод-обработчик этой сущности/объекта данных. Метод-обработчик может вернуть
только ошибку или nil. Если обработчик вернул ошибку, просто логируешь ее
и переходишь к следующему.

Как реализовать метод-обработчик, смотри секцию "Работа с Locker" этого файла.

#### Kafka-воркеры

Кафка-воркер - это воркер, в методе Run() которого запускается Kafka consumer, 
слушающий набор топиков с группой. Топики/группа задаются в конфиге.

При получении каждого сообщения, парси его в соответствующую DTO-структуру 
и передавай приватному методу-обработчику. Метод-обработчик может вернуть
только ошибку или nil. Если обработчик вернул ошибку, пробрасываешь ошибку консумеру.

Как реализовать метод-обработчик, смотри секцию "Работа с Locker" этого файла.

## OpenAPI / gRPC

- Ошибки: схемы `Error` выносятся в components, в ответах делаем `$ref`, описания/контент остаются inline. Пустые 200-ответы — схема `Empty`. Это требование повторяется во всех сервисах.
- Перенос `*Request`/`*Response` в `components/schemas`, content inline; теги у методов могут быть переопределены одним значением (Partnership и др.).
- Опциональные поля: если из сервисов приходит пустая строка, в ответе отдаём unset/null. Новые поля в запросах/ответах нужно пробрасывать до бизнес-слоя.
- gRPC методы добавляем вместе с proto-структурами и реализацией сервера; зависимости протягиваем через DI.

## Работа с сущностями

- Новые поля: задавай дефолты как в постановке. Помни про связанные журналы, если они есть у этой сущности (например, у сущности Transaction может быть связанная сущность TransactionJournal - если она есть, то все изменения транслируй также в нее). В гугланговых моделях соблюдай nullable/optional типы.
- Новые сущности: полный CRUD в репозиториях, миграции в `migrations`, без FK/edges если явно не просили.
- При любых изменениях в сущностях следи чтобы во всех методах репозиториев, работающих с этими сущносятми, были внесены актуальные изменения. Например: добавил поле в сущность, сразу же внеси нужные правки во все методы репозитория, чтобы при create/update/save это поле обязательно сохранялось в БД.
- Во все новые сущности по умолчанию всегда добавляй стандартные поля created_at, updated_at.

## Логи и мониторинг

- Логируй ключевые действия и ошибки, но многие ошибки уведомлений не должны прерывать поток.
- Для Kafka-консумеров в логах ошибок добавляй список топиков.
- HTTP-серверы: middleware на логирование возврата ошибочных статусов.

## Документация/тон

- README/описания иногда требуются с легким сарказмом и дружелюбным тоном. Схемы/диаграммы включаются в README, файлы кладутся в корень, ссылки добавляются в текст.
