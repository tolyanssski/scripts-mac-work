# AGENTS: базовые ожидания по задачам

Этот файл — шпаргалка по типовым требованиям во всех git-проектах в `~/projects`.
Все эти проекты являются частью одного большого продукта: каждый проект - это или микросервис, или общая библиотека, используемая другими проектами. 
Пользуйся текущей шпаргалкой как стартовой инструкцией.
Если новая задача похожа на один из кейсов ниже — применяй соответствующий набор действий без повторных подсказок.

## Работа с миграциями

Несмотря на то, что в проектах используются ORM-системы (либо ent, либо gorm), миграции у нас все ручные в виде простых SQL-файлов для Postgres.
У некоторых проектов есть своя БД, и соответственно своя папка migrations (лежит всегда в корне проекта), 
куда надо складывать новые файлы с миграциями. Если в проекте используется Atlas,
то нужно сгенерировать atlas.sum.

Но также есть проекты, у которых своей БД нет (используется общая), и миграции лежат
в отдельном git-проекте.
Если ты работаешь над таким проектом и тебе требуется сделать миграцию, но в проекте нет папки migrations (в корне проекта), просто создай новую папку migrations и
добавь туда SQL-файл. Я потом сам руками ее перенесу куда надо.

В проектах нужно создавать только UP-миграции. Миграций "down" (отката сделанных изменений) создавать не нужно.

### Формат файла миграций

Миграции складываются в папку migrations в корне проекта. Формат: SQL-файл,
с именем в формате `<YYYYMMDDhhmmss>_<названиеМиграцииНаАнгл>.sql`. Где `<YYYYMMDDhhmmss>` - текущее дата/время в заданном формате, например: 20260114090857 (пример для текущего даты/времени 2025-01-14 09:08:57).

### В каких случаях требуется создание новой миграции

Если в задаче ничего не написано про миграции, но при этом выполнение задачи
подразумевает создание новой или изменение существующей ORM-сущности (в ent/gorm),
всегда делай новую миграцию с этими изменениями, в соответствии с инструкцией выше. 

## Общие подходы

- По умолчанию в качестве идентификаторов везде используй uuid v7;
- Всегда обновляй сущности вместе с инфраструктурой: поля в ent/gorm + миграции Postgres, правки репозиториев, DTO, сервисных слоев, OpenAPI/gRPC, тестов и данных (data-migration скрипты, если нужно проставить значения старым строкам).
- Конфиги с secrets/creds/external_urls дублируй env-переменными: значения должны идти из YAML, но переопределяться через переменные окружения. Данный пункт касается только значений конфига, содержащих те или иные credentials для подключения к внешним системам (secret key, api key, external_system_url и аналогичные). 
- Локи обязательны при гонках: ключи строятся из сервиса/метода и бизнес-идентификаторов (userID, accountID, address и т.п.), TTL ставят только если явно указано.
- Побочные эффекты (Kafka producing, отправка e-mail/SMS, создание/отправка уведомлений) выноси из БД-транзакций; ошибки уведомлений чаще логируются и не прерывают основной флоу.

## Работа с зависимостями пакета/сервиса

Под "сервисом" внутри проекта подразумевается структура, лежащая внутри какого-либо пакета, имеющая свой конструктор, зависимости и публичные/приватные методы.

Если требуется добавить зависимость в сервис, то как правило нужно сначала
в пакете сервиса создать локальный интерфейс, описывающий методы (подсмотри методы в конкретной зависимости). После этого в конструктор сервиса пробрасывай аргументом
этот локальный интерфейс. А уже на уровне DI (на этапе сборки приложения) подставляй
конкретный инстанс этой зависимости.

Если зависимость проброшена через конструктор сервиса и является его приватным полем,
то подразумевай что во всех рабочих методах сервиса это поле точно не nil.
Можешь проверять на nil прямо конструкторе и возвращать из конструктора error, но это
не обязательно.
Проверять на nil эти поля-зависимости в рабочей логике не нужно.

## Работа с конфигурацией

### У каждого пакета/сервиса свой локальный Config

У каждого пакета/сервиса, если требуется, должна быть своя структура `Config`, локальная по отношению к пакету (лежит внутри конкретного пакета, к которому относится). 
В этой структуре `Config` находятся все нужные поля.
В некоторых случаях структура `Config` может находиться в другом месте, и там где это так, используй то что 
уже есть. Также в некоторых уже существующих пакетах иногда структура конфигурации может называться по-другому (Params, Options и тд) - в этом случае пользуйся тем что есть.

Для новых пакетов/сервисов строго следуй правилу "структура конфига сервиса рядом с сервисом в одном с ним пакете" и называй структуру всегда `Config`.

Сам сервис в качестве одной из своих зависимостей принимает эту локальную структуру `Config`, которая подается
ему в конструктор и пишется в локальное поле `config` или `conf`.

Пример:

```go
package currencies

// Конфигурация сервиса Currencies
type FixerConfig struct {
	Endpoint string `yaml:"endpoint"`
	APIKey   string `yaml:"apiKey"`
}
type Config struct {
	BaseCurrency      string      `yaml:"baseCurrency"`
	PrimaryCurrencies []string    `yaml:"primaryCurrencies"`
	Fixer             FixerConfig `yaml:"fixer"`
}

// Сама структура сервиса Currencies
type Currencies struct {
	logger    Logger
	conf      Config
	repo      Repository
	providers []Provider

	ratesToBase map[string]float64
	mu          sync.RWMutex
}

// Конструктор сервиса Currencies
func New(logger Logger, conf Config, repo Repository, providers []Provider) *Currencies {
	return &Currencies{
		logger:    logger,
		conf:      conf,
		repo:      repo,
		providers: providers,
	}
}

```

Хотя в примере все показано в одном файле, `Config` можно вынести в отдельный файл `config.go`. 
Главное, чтобы он лежал в том же пакете.
В полях конфига всегда указывай yaml-теги.

### Сборка конфига - в отдельном общем пакете

В проекте внутри `internal` должен находиться один общий пакет `config`, который занимается загрузкой/сборкой
всех конфигов других пакетов.
В этом пакете главная структура `Config` в виде полей содержит данных конфигов других пакетов, примерно как показано в этом примере. То есть: общий пакет `config` знает обо всех локальных конфигах, но локальные конфиги
ничего не знают об общем `config`.
Также в этом общем пакете лежит файл `config.yml` с реальным данными конфигурации всех пакетов. Этот yaml-файл
встраивается в приложение через `embed`.
И в конструкторе вызывается библиотека `viper`, загружающая все данные из yaml-файла в поля конфига.
Пример:

```go
package config

import (...)

//go:embed config.yml
var configData string

type Config struct {
	WelcomeBonus welcomebonus.Config `yaml:"welcomeBonus"`
	Currencies   currencies.Config   `yaml:"currencies"`
	Rebate       rebate.Config       `yaml:"rebate"`
	DepositBonus depositbonus.Config `yaml:"depositBonus"`
	Balancer     balancer.Config     `yaml:"balancer"`
	MtEvents     mtevents.Config     `yaml:"mtEvents"`
	Rights       rights.Config       `yaml:"rights"`
	CryptoLinks  cryptolinks.Config  `yaml:"cryptolinks"`
}

func Load() (Config, error) {
	var err error
	config := Config{}
	viper.SetConfigType("yaml")

	file := io.NopCloser(strings.NewReader(configData))
	defer func() { _ = file.Close() }()

	err = viper.ReadConfig(file)
	if err != nil {
		return Config{}, err
	}
	err = viper.Unmarshal(&config)
	if err != nil {
		return Config{}, err
	}

	return config, nil
}
```

### Некоторые поля переопределяются переменными окружения

Часть полей (но далеко не все) переопределяются переменными окружения. Какие именно поля 
должны переопределяться из `env`, указывается в отдельной структуре `Environment`, которая тоже находится
в общем `config`-пакете. 
Если что-то берется из переменных окружения, то у конфига должен быть конструктор, принимающий на входе
структуру `Environment` со всеми полями, и внутри конструктора делается перезапись полей конфига теми что
пришли в `Environment`.

В каждой задаче я обычно явным оборазом говорю, какие переменные конфига должны браться из окружения.
Если про какие-то поля конфига я такого не сказал, значит они хранятся только в конфиге и больше нигде (по ним
не нужно использовать `env`'ы).

Пример того как может выглядеть общий `Config` с переменными окружения:

```go
package config

import (...)

//go:embed config.yml
var configData string

type Environment struct {
	FixerAPIKey string
}

type Config struct {
	WelcomeBonus welcomebonus.Config `yaml:"welcomeBonus"`
	Currencies   currencies.Config   `yaml:"currencies"`
	Rebate       rebate.Config       `yaml:"rebate"`
	DepositBonus depositbonus.Config `yaml:"depositBonus"`
	Balancer     balancer.Config     `yaml:"balancer"`
	MtEvents     mtevents.Config     `yaml:"mtEvents"`
	Rights       rights.Config       `yaml:"rights"`
	CryptoLinks  cryptolinks.Config  `yaml:"cryptolinks"`
}

func Load(e Environment) (Config, error) {
	var err error
	config := Config{}
	viper.SetConfigType("yaml")

	file := io.NopCloser(strings.NewReader(configData))
	defer func() { _ = file.Close() }()

	err = viper.ReadConfig(file)
	if err != nil {
		return Config{}, err
	}
	err = viper.Unmarshal(&config)
	if err != nil {
		return Config{}, err
	}

	if e.FixerAPIKey != "" {
		config.Currencies.Fixer.APIKey = e.FixerAPIKey
	}

	return config, nil
}
```

И в таком случае DI-сборка приложения делается вот так:

```go
conf, err := config.Load(
	config.Environment{
		FixerAPIKey: os.Getenv("FIXER_API_KEY"),
	}
)
```

### Если нужно добавить новые поля в конфиг и/или есть инструкция брать что-то из конфига

В этом случае делай следующее:
- если конфига у пакета/сервиса совсем нет, создай его и пробрось через DI в сервис;
- новые поля добавь как в структуру конфига, так и в yaml-файл, лежащий в общем config-пакете;
- если видишь, что yaml-файл, из которого грузится конфиг, лежит в другом месте (не по тем правилам которые указаны здесь), то пользуйся тем что уже есть;
- для новых полей: переопределение полей из переменных окружения делай только тогда, когда об этом явным образом указано в задаче.


## Работа с Locker

В проектах при работе с сущностями часто используется паттерн `pessimitic offline lock` (by Martin Fowler). Это значит в ряде задач (особенно выполняющихся в фоне)
перед началом работы с сущностью (апдейтом и тд) ставится лок путем создания специальной временной записи в БД или Redis или еще каком-либо хранилище.
В нашем продукте во всех проектах и сервисах используется лок через Redis. В проектах
проброшен стандартный Locker из общей библиотеки. Он реализует интерфейс Locker.

Если требуется поставить лок на сущность/какой-то другой идентификатор в логике какого-то сервиса, делай следующее:
- убедись что у этого сервиса уже есть зависимость Locker. Если нет, пробрось через DI;
- работу с залоченной сущностью/другим идентификатором по умолчанию выноси в отдельный приватный метод-обработчик;
- в методе-обработчике в самом начале ставь лок, потом после обработки ошибки сразу же defer unlock с этим же ключом;
- ключ каждого лока должен быть строкой в формате: `<project_name>:<package_name>:<structure_name>:<method_name>:<ID>`, где ID - это либо ID блокируемой сущности (если блокируется сущность), либо само значение блокируемого идентификатора (если блокируется что-то другое);
- никогда не делай сборку ключа лока inline: выноси сборку в специальный приватный метод - билдер лок-ключа (под каждый лок свой метод-билдер);

### Важное про реализацию метода-обработчика, если блокируется сущность БД

Если ставится лок на БД-сущность, то в метод-обработчик пробрасывай на экземпляр сущности, а только ее ID.
После установки лока в методе-обработчике делай заново получение инстанса сущности из репозитория по ее ID, чтобы гарантировать что обработка сущности будет идти со свежими данными, актуальными на момент успешного лока.

## Работа с воркерами / фоновыми горутинами

В контексте наших проектов слова "воркер" и "фоновая горутина" - синонимы.
Воркер - это отдельный сервис внутри проекта, который запускается в фоновом режиме
одновременно со стартом всего приложения, в виде самостоятельной горутины.
Воркер имеет метод запуска `Run(ctx) error`, на входе ему подается базовый контекст
приложения. Метод должен быть блокирующим, и единственный способ выхода из метода - это возвращенная ошибка.
Следовательно запускать надо при старте приложения как часть errgroup или аналогов.

Пример кода, запускающего воркеры (app.Run() всего приложения со всеми воркерами внутри):

```go
func (a *App) Run(ctx context.Context) error {
	ctx, cancel := context.WithCancel(ctx)
	go func() {
		<-a.done
		cancel()
	}()

	errs := make(chan error)

	go func() {
		err := a.eventsService.Run(ctx)
		if err != nil {
			select {
			case errs <- errors.Wrap(err, "eventsService.Run"):
			case <-ctx.Done():
			}
			return
		}
	}()

	go func() {
		err := a.rightsService.Run(ctx)
		if err != nil {
			select {
			case errs <- errors.Wrap(err, "rightsService.Run"):
			case <-ctx.Done():
			}
			return
		}
	}()

	select {
	case err := <-errs:
		_ = a.Shutdown()
		return err
	case <-ctx.Done():
		return nil
	}
}
```

Если в конкретном проекте используется другой подход к запуску фоновых воркеров, используй его (встраивай новый воркер в уже сложившийся код запуска).

### Что делать, если требуется создать новый воркер

- Если не сказано иное, создай новый пакет, и внутри него сервис с названием таким же как пакет. Если не указано как его назвать, придумай название сам на основе того что будет делать этот новый воркер;
- Пробрось в него зависимости через DI: как минимум Logger и Locker обязательно, а также Kafka consumer, если это кафка-воркер. А также те зависимости что требуются в задаче;
- Реализуй метод Run(): способ реализации зависит от типа воркера, смотри пункты ниже.

#### БД-воркеры

БД-воркер - это просто бесконечный цикл, который раз в определенный период времени
делает запрос в БД по заданным критериям, получает выборку сущностей и далее 
производит обработку каждой сущности в отдельном приватном методе.

В некоторых случаях может быть не выборка сущностей, а выборка каких-либо других данных.

Получив выборку, проходишься по всему полученному массиву, дергаешь приватный метод-обработчик этой сущности/объекта данных. Метод-обработчик может вернуть
только ошибку или nil. Если обработчик вернул ошибку, просто логируешь ее
и переходишь к следующему.

Как реализовать метод-обработчик, смотри секцию "Работа с Locker" этого файла.

#### Kafka-воркеры

Кафка-воркер - это воркер, в методе Run() которого запускается Kafka consumer, 
слушающий набор топиков с группой. Топики/группа задаются в конфиге.

При получении каждого сообщения, парси его в соответствующую DTO-структуру 
и передавай приватному методу-обработчику. Метод-обработчик может вернуть
только ошибку или nil. Если обработчик вернул ошибку, пробрасываешь ошибку консумеру.

Как реализовать метод-обработчик, смотри секцию "Работа с Locker" этого файла.

## OpenAPI / gRPC

- Ошибки: схемы `Error` выносятся в components, в ответах делаем `$ref`, описания/контент остаются inline. Пустые 200-ответы — схема `Empty`. Это требование повторяется во всех сервисах.
- Перенос `*Request`/`*Response` в `components/schemas`, content inline; теги у методов могут быть переопределены одним значением (Partnership и др.).
- Опциональные поля: если из сервисов приходит пустая строка, в ответе отдаём unset/null. Новые поля в запросах/ответах нужно пробрасывать до бизнес-слоя.
- gRPC методы добавляем вместе с proto-структурами и реализацией сервера; зависимости протягиваем через DI.
- ВАЖНО: Если есть инструкция добавить новые методы OpenAPI, всегда подразумевается, что нужно также сделать их реализацию, включая все необходимое - сервисные методы, методы репозитория и т.д.

## Работа с сущностями

- Новые поля: задавай дефолты как в постановке. Помни про связанные журналы, если они есть у этой сущности (например, у сущности Transaction может быть связанная сущность TransactionJournal - если она есть, то все изменения транслируй также в нее). В гугланговых моделях соблюдай nullable/optional типы.
- Новые сущности: полный CRUD в репозиториях, миграции в `migrations`, без FK/edges если явно не просили.
- При любых изменениях в сущностях следи чтобы во всех методах репозиториев, работающих с этими сущносятми, были внесены актуальные изменения. Например: добавил поле в сущность, сразу же внеси нужные правки во все методы репозитория, чтобы при create/update/save это поле обязательно сохранялось в БД.
- Во все новые сущности по умолчанию всегда добавляй стандартные поля created_at, updated_at.

## Логи и мониторинг

- Логируй ключевые действия и ошибки, но многие ошибки уведомлений не должны прерывать поток.
- Для Kafka-консумеров в логах ошибок добавляй список топиков.
- HTTP-серверы: middleware на логирование возврата ошибочных статусов.

## Документация/тон

- README/описания иногда требуются с легким сарказмом и дружелюбным тоном. Схемы/диаграммы включаются в README, файлы кладутся в корень, ссылки добавляются в текст.
